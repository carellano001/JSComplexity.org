<h3>About complexity</h3>

<p>
    Complexity is the quality of
    consisting of many interrelated parts.
    When software consists of many interrelated parts,
    it becomes more difficult to reason about.
    Software that is difficult to reason about
    is a more fertile breeding ground for bugs
    than software that is simple.
</p>

<p>
    Every problem space contains some level of inherent complexity,
    which is shared by all possible solutions.
    However, as programmers,
    we can reduce the complexity of our chosen solutions
    by limiting the interrelatedness of their constituent components.
    This is commonly referred to as favouring
    <a href="http://en.wikipedia.org/wiki/Cohesion_(computer_science)">cohesion</a>
    over <a href="http://en.wikipedia.org/wiki/Coupling_(computer_programming)">coupling</a>,
    and forms the bedrock on which axioms
    such as the <a href="http://www.objectmentor.com/resources/articles/srp.pdf">single responsibility principle</a>
    are built.
</p>

<p>
    In codebases that are large and/or unfamiliar,
    it can be difficult to know
    whether regions of complexity exist
    and where they might be.
    By defining metrics of complexity,
    the search for offending components
    can be automated
    and brought into the existing build process
    alongside other forms of static analysis
    and unit tests.
    Although the metrics themselves are far from perfect,
    they can be useful in helping to identify
    areas of code that warrant closer inspection.
    They can also be tracked over time,
    as an indicator of the direction that
    overall code quality
    may be moving in.
</p>

<p>
    The metrics that are reported by this site are generated by
    <a href="https://github.com/philbooth/complexityReport.js">a tool</a>,
    available from
    <a href="https://npmjs.org/">npm</a>
    as
    <a href="https://npmjs.org/package/complexity-report">complexity-report</a>,
    which can be used in such a way.
    Currently, it is able to report on
    four different types of complexity metric:
    <a href="http://en.wikipedia.org/wiki/Source_lines_of_code">lines of code</a>,
    <a href="http://en.wikipedia.org/wiki/Cyclomatic_complexity">cyclomatic complexity</a>,
    <a href="http://en.wikipedia.org/wiki/Halstead_complexity_measures">Halstead complexity measures</a> and
    <a href="http://www.virtualmachinery.com/sidebar4.htm">the maintainability index</a>.
</p>

<ul class="complexity">
    <li>
        <h4 class="metric-name">Lines of code (LOC)</h4>

        <p>
            This can be either physical
            (a count of the actual lines in the file)
            or logical
            (a count of the imperative statements).
            The physical count is widely considered to be a less useful metric
            because it is easily subverted
            by collecting multiple statements on a single line of code.
            However it should be noted that the logical count can be similarly flawed,
            since the tersest expression of a solution
            is not necessarily the optimal one.
        </p>
    </li>

    <li>
        <h4 class="metric-name">Cyclomatic complexity</h4>

        <p>
            Created by Thomas J. McCabe in 1976,
            this metric counts
            the number of distinct paths through
            a block of code.
            It takes its name from
            counting the number of cycles in
            the program flow control graph.
            Lower values are better;
            McCabe suggested using ten
            as a threshold value,
            beyond which modules should be split
            into smaller units.
        </p>
    </li>

    <li>
        <h4 class="metric-name">Halstead complexity measures</h4>

        <p>
            In 1977, Maurice Halstead developed a set of metrics
            which are calculated based on
            the number of distinct operators,
            the number of distinct operands,
            the total number of operators
            and the total number of operands
            in each function.
            This site picks out three Halstead measures in particular:
            difficulty, volume and effort.
        </p>

        <ul>
            <li>
                <h5 class="metric-name">Difficulty</h5>

                <div class="equation">
                    <pre><code>    (# distinct operators / 2) *
        (# operands / # distinct operands)</code></pre>
                </div>
            </li>

            <li>
                <h5 class="metric-name">Volume</h5>

                <div class="equation">
                    <pre><code>    (# operators + # operands) *
        log2(# distinct operators + # distinct operands)</code></pre>
                </div>
            </li>

            <li>
                <h5 class="metric-name">Effort</h5>

                <div class="equation">
                    <pre><code>    difficulty * volume</code></pre>
                </div>
            </li>
        </ul>
    </li>

    <li>
        <h4 class="metric-name">Maintainability index</h4>

        <p>
            Designed in 1991
            by Paul Oman and Jack Hagemeister
            at the University of Idaho,
            this metric is calculated
            at the whole program
            or module level
            from averages of the other 3 metrics,
            using the following formula:
        </p>

        <div class="equation">
            <pre><code>    171 -
        (3.42 * ln(mean effort)) -
        (0.23 * ln(mean cyclomatic complexity)) -
        (16.2 * ln(mean logical LOC))</code></pre>
        </div>

        <p>
            Values are on a scale
            ranging from negative infinity
            up to 171,
            with greater numbers indicating a higher level of maintainability.
            In their original paper,
            Oman and Hagemeister identified 65 as the threshold value
            below which a program should be considered difficult to maintain.
        </p>
    </li>
</ul>
